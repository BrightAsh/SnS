import openai
from voice.listener import listen_for_command
from utils.tts import speak
from detection.model_loader import load_model
from detection.detector import detect_objects
from search.naver_api import search_naver_shopping
from utils.helpers import extract_object_number
from embedding.clip_text_predictor import predict_label
from gpt.product_name_generator import generate_product_name

# GPT API í‚¤ ì„¤ì •
openai.api_key = "YOUR_OPENAI_API_KEY"

class AI_Agent:
    def __init__(self):
        self.model = load_model()
        self.detected_objects = []
        self.last_image = None

    def listen_for_command(self):
        command = listen_for_command()
        return command

    def interpret_command(self, command):
        """
        GPTë¡œ ëª…ë ¹ì–´ë¥¼ í•´ì„í•˜ì—¬, ëª…ë ¹ì˜ ì˜ë¯¸ë¥¼ ì¶”ì¶œí•˜ê³  íˆ´ì„ ì„ íƒí•©ë‹ˆë‹¤.
        """
        prompt = f"ì‚¬ìš©ì ëª…ë ¹: '{command}'. ì´ ëª…ë ¹ì„ ì´í•´í•˜ê³ , ì‹¤í–‰í•  íˆ´ì„ ì„ íƒí•´ ì£¼ì„¸ìš”. ì˜ˆë¥¼ ë“¤ì–´, 'ê°ì²´ íƒì§€', 'ì œí’ˆ ê²€ìƒ‰' ë“±."
        response = openai.Completion.create(
            model="text-davinci-003",
            prompt=prompt,
            max_tokens=60
        )
        interpreted_command = response.choices[0].text.strip()
        return interpreted_command

    def execute_tool(self, interpreted_command):
        """
        í•´ì„ëœ ëª…ë ¹ì— ë§ëŠ” íˆ´ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
        """
        if interpreted_command == "ì œí’ˆ ì¸ì‹":
            return self.trigger_object_detection()
        elif interpreted_command == "ì œí’ˆ ê²€ìƒ‰":
            return self.search_product()
        else:
            speak("ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            return None

    def trigger_object_detection(self):
        """
        ê°ì²´ íƒì§€ ì‹¤í–‰
        """
        print(f"[ëª…ë ¹ ê°ì§€] ê°ì²´ ì¸ì‹ ì‹œì‘")
        self.last_image = capture_screen()
        self.detected_objects = detect_objects(self.model, self.last_image)
        speak("ëª‡ ë²ˆ ì œí’ˆì„ í™•ì¸í• ê¹Œìš”?")
        return self.process_user_selection()

    def process_user_selection(self):
        """
        ì‚¬ìš©ìê°€ ì„ íƒí•œ ê°ì²´ ë²ˆí˜¸ë¥¼ ì²˜ë¦¬í•˜ê³ , ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
        """
        n_obj = listen_for_command()

        if n_obj:
            object_idx = extract_object_number(n_obj)
            if object_idx is not None and 0 <= object_idx < len(self.detected_objects):
                cropped = crop_object(self.last_image, self.detected_objects[object_idx])
                clip_label = predict_label(cropped)
                product_name = generate_product_name(cropped, clip_label)
                url = search_naver_shopping(product_name)
                if url:
                    speak("ì œí’ˆ íŒë§¤ í˜ì´ì§€ë¥¼ ì—´ì–´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.")
                    webbrowser.open(url)
                else:
                    speak("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                speak("ìœ íš¨í•œ ì œí’ˆ ë²ˆí˜¸ë¥¼ ë§í•´ì£¼ì„¸ìš”.")
        return None

    def search_product(self):
        """
        ì œí’ˆ ê²€ìƒ‰ ì‹¤í–‰
        """
        speak("ì–´ë–¤ ì œí’ˆì„ ì°¾ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?")
        product_name = listen_for_command()
        url = search_naver_shopping(product_name)
        if url:
            speak("ì œí’ˆ íŒë§¤ í˜ì´ì§€ë¥¼ ì—´ì–´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.")
            webbrowser.open(url)
        else:
            speak("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

def run():
    agent = AI_Agent()

    while True:
        # ğŸ¤ ëª…ë ¹ ëŒ€ê¸°
        command = agent.listen_for_command()

        # ëª…ë ¹ í•´ì„ ë° ì‹¤í–‰
        interpreted_command = agent.interpret_command(command)
        agent.execute_tool(interpreted_command)

if __name__ == "__main__":
    run()
